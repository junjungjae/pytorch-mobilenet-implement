{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from jjjMobileNet import MobileNetv1\n",
    "from conf import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = config['data']['img_size']\n",
    "num_classes = config['data']['num_classes']\n",
    "save_folder = config['data']['save_weights_dir']\n",
    "\n",
    "batch_size = config['param']['batch_size']\n",
    "width_param = config['param']['width_ratio']\n",
    "learning_rate = config['param']['lr']\n",
    "num_epochs = config['param']['num_epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "output size: torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.randn((3, 3, img_size, img_size)).to(device)\n",
    "print(device)\n",
    "\n",
    "model = MobileNetv1(width_param=width_param, num_classes=num_classes).to(device)\n",
    "output = model(x)\n",
    "\n",
    "print('output size:', output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 28, 111, 111]             784\n",
      "       BatchNorm2d-2         [-1, 28, 111, 111]              56\n",
      "              ReLU-3         [-1, 28, 111, 111]               0\n",
      "            Conv2d-4         [-1, 28, 111, 111]             252\n",
      "       BatchNorm2d-5         [-1, 28, 111, 111]              56\n",
      "             ReLU6-6         [-1, 28, 111, 111]               0\n",
      "            Conv2d-7         [-1, 57, 111, 111]           1,596\n",
      "       BatchNorm2d-8         [-1, 57, 111, 111]             114\n",
      "             ReLU6-9         [-1, 57, 111, 111]               0\n",
      "DepthwiseSeparable-10         [-1, 57, 111, 111]               0\n",
      "           Conv2d-11           [-1, 57, 56, 56]             513\n",
      "      BatchNorm2d-12           [-1, 57, 56, 56]             114\n",
      "            ReLU6-13           [-1, 57, 56, 56]               0\n",
      "           Conv2d-14          [-1, 115, 56, 56]           6,555\n",
      "      BatchNorm2d-15          [-1, 115, 56, 56]             230\n",
      "            ReLU6-16          [-1, 115, 56, 56]               0\n",
      "DepthwiseSeparable-17          [-1, 115, 56, 56]               0\n",
      "           Conv2d-18          [-1, 115, 56, 56]           1,035\n",
      "      BatchNorm2d-19          [-1, 115, 56, 56]             230\n",
      "            ReLU6-20          [-1, 115, 56, 56]               0\n",
      "           Conv2d-21          [-1, 115, 56, 56]          13,225\n",
      "      BatchNorm2d-22          [-1, 115, 56, 56]             230\n",
      "            ReLU6-23          [-1, 115, 56, 56]               0\n",
      "DepthwiseSeparable-24          [-1, 115, 56, 56]               0\n",
      "           Conv2d-25          [-1, 115, 28, 28]           1,035\n",
      "      BatchNorm2d-26          [-1, 115, 28, 28]             230\n",
      "            ReLU6-27          [-1, 115, 28, 28]               0\n",
      "           Conv2d-28          [-1, 230, 28, 28]          26,450\n",
      "      BatchNorm2d-29          [-1, 230, 28, 28]             460\n",
      "            ReLU6-30          [-1, 230, 28, 28]               0\n",
      "DepthwiseSeparable-31          [-1, 230, 28, 28]               0\n",
      "           Conv2d-32          [-1, 230, 28, 28]           2,070\n",
      "      BatchNorm2d-33          [-1, 230, 28, 28]             460\n",
      "            ReLU6-34          [-1, 230, 28, 28]               0\n",
      "           Conv2d-35          [-1, 230, 28, 28]          52,900\n",
      "      BatchNorm2d-36          [-1, 230, 28, 28]             460\n",
      "            ReLU6-37          [-1, 230, 28, 28]               0\n",
      "DepthwiseSeparable-38          [-1, 230, 28, 28]               0\n",
      "           Conv2d-39          [-1, 230, 14, 14]           2,070\n",
      "      BatchNorm2d-40          [-1, 230, 14, 14]             460\n",
      "            ReLU6-41          [-1, 230, 14, 14]               0\n",
      "           Conv2d-42          [-1, 460, 14, 14]         105,800\n",
      "      BatchNorm2d-43          [-1, 460, 14, 14]             920\n",
      "            ReLU6-44          [-1, 460, 14, 14]               0\n",
      "DepthwiseSeparable-45          [-1, 460, 14, 14]               0\n",
      "           Conv2d-46          [-1, 460, 14, 14]           4,140\n",
      "      BatchNorm2d-47          [-1, 460, 14, 14]             920\n",
      "            ReLU6-48          [-1, 460, 14, 14]               0\n",
      "           Conv2d-49          [-1, 460, 14, 14]         211,600\n",
      "      BatchNorm2d-50          [-1, 460, 14, 14]             920\n",
      "            ReLU6-51          [-1, 460, 14, 14]               0\n",
      "DepthwiseSeparable-52          [-1, 460, 14, 14]               0\n",
      "           Conv2d-53          [-1, 460, 14, 14]           4,140\n",
      "      BatchNorm2d-54          [-1, 460, 14, 14]             920\n",
      "            ReLU6-55          [-1, 460, 14, 14]               0\n",
      "           Conv2d-56          [-1, 460, 14, 14]         211,600\n",
      "      BatchNorm2d-57          [-1, 460, 14, 14]             920\n",
      "            ReLU6-58          [-1, 460, 14, 14]               0\n",
      "DepthwiseSeparable-59          [-1, 460, 14, 14]               0\n",
      "           Conv2d-60          [-1, 460, 14, 14]           4,140\n",
      "      BatchNorm2d-61          [-1, 460, 14, 14]             920\n",
      "            ReLU6-62          [-1, 460, 14, 14]               0\n",
      "           Conv2d-63          [-1, 460, 14, 14]         211,600\n",
      "      BatchNorm2d-64          [-1, 460, 14, 14]             920\n",
      "            ReLU6-65          [-1, 460, 14, 14]               0\n",
      "DepthwiseSeparable-66          [-1, 460, 14, 14]               0\n",
      "           Conv2d-67          [-1, 460, 14, 14]           4,140\n",
      "      BatchNorm2d-68          [-1, 460, 14, 14]             920\n",
      "            ReLU6-69          [-1, 460, 14, 14]               0\n",
      "           Conv2d-70          [-1, 460, 14, 14]         211,600\n",
      "      BatchNorm2d-71          [-1, 460, 14, 14]             920\n",
      "            ReLU6-72          [-1, 460, 14, 14]               0\n",
      "DepthwiseSeparable-73          [-1, 460, 14, 14]               0\n",
      "           Conv2d-74          [-1, 460, 14, 14]           4,140\n",
      "      BatchNorm2d-75          [-1, 460, 14, 14]             920\n",
      "            ReLU6-76          [-1, 460, 14, 14]               0\n",
      "           Conv2d-77          [-1, 460, 14, 14]         211,600\n",
      "      BatchNorm2d-78          [-1, 460, 14, 14]             920\n",
      "            ReLU6-79          [-1, 460, 14, 14]               0\n",
      "DepthwiseSeparable-80          [-1, 460, 14, 14]               0\n",
      "           Conv2d-81            [-1, 460, 7, 7]           4,140\n",
      "      BatchNorm2d-82            [-1, 460, 7, 7]             920\n",
      "            ReLU6-83            [-1, 460, 7, 7]               0\n",
      "           Conv2d-84            [-1, 921, 7, 7]         423,660\n",
      "      BatchNorm2d-85            [-1, 921, 7, 7]           1,842\n",
      "            ReLU6-86            [-1, 921, 7, 7]               0\n",
      "DepthwiseSeparable-87            [-1, 921, 7, 7]               0\n",
      "           Conv2d-88            [-1, 921, 7, 7]           8,289\n",
      "      BatchNorm2d-89            [-1, 921, 7, 7]           1,842\n",
      "            ReLU6-90            [-1, 921, 7, 7]               0\n",
      "           Conv2d-91            [-1, 921, 7, 7]         848,241\n",
      "      BatchNorm2d-92            [-1, 921, 7, 7]           1,842\n",
      "            ReLU6-93            [-1, 921, 7, 7]               0\n",
      "DepthwiseSeparable-94            [-1, 921, 7, 7]               0\n",
      "AdaptiveAvgPool2d-95            [-1, 921, 1, 1]               0\n",
      "           Linear-96                   [-1, 10]           9,220\n",
      "================================================================\n",
      "Total params: 2,606,201\n",
      "Trainable params: 2,606,201\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 120.95\n",
      "Params size (MB): 9.94\n",
      "Estimated Total Size (MB): 131.46\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, img_size, img_size), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "5000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "path2data = config['data']['dataset']\n",
    "\n",
    "if not os.path.exists(path2data):\n",
    "    os.mkdir(path2data)\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "# load dataset\n",
    "train_ds = datasets.STL10(path2data, split='train', download=True, transform=transforms.ToTensor())\n",
    "val_ds = datasets.STL10(path2data, split='test', download=True, transform=transforms.ToTensor())\n",
    "\n",
    "print(len(train_ds))\n",
    "print(len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize(img_size)\n",
    "])\n",
    "\n",
    "# apply transformation to dataset\n",
    "train_ds.transform = transformation\n",
    "val_ds.transform = transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
    "opt = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = ReduceLROnPlateau(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = {'train': [], 'val': []}\n",
    "metric_history = {'train': [], 'val': []}\n",
    "\n",
    "def calc_batch_metric(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    metric = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return metric\n",
    "\n",
    "def calc_batch_loss(loss_func, output, target, opt=None):\n",
    "    batch_loss = loss_func(output, target)\n",
    "    batch_metric = calc_batch_metric(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    return batch_loss.item(), batch_metric\n",
    "\n",
    "def loss_epoch(model, loss_func, data_loader, opt=None):\n",
    "    epoch_loss, epoch_metric = 0, 0\n",
    "    data_len = len(data_loader.dataset)\n",
    "    \n",
    "    for xd, yd in data_loader:\n",
    "        xd = xd.to(device)\n",
    "        yd = yd.to(device)\n",
    "        \n",
    "        output = model(xd)\n",
    "        \n",
    "        batch_loss, batch_metric = calc_batch_loss(loss_func=loss_func, output=output, target=yd, opt=opt)\n",
    "        \n",
    "        epoch_loss += batch_loss\n",
    "        \n",
    "        if batch_metric is not None:\n",
    "            epoch_metric += batch_metric\n",
    "        \n",
    "    return_loss = epoch_loss / data_len\n",
    "    return_metric = epoch_metric / data_len\n",
    "    \n",
    "    return np.round(return_loss, 5), np.round(return_metric, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning Rate: 0.01\n",
      "Epoch: 0 Time: 79.0s Train Loss: 0.06089, Validation Loss: 0.0561, Train Accuracy: 24.92%, Validation Accuracy: 27.025%\n",
      "save best weights\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 1 Time: 75.0s Train Loss: 0.05362, Validation Loss: 0.0539, Train Accuracy: 30.819999999999997%, Validation Accuracy: 29.425%\n",
      "save best weights\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 2 Time: 75.0s Train Loss: 0.05244, Validation Loss: 0.05015, Train Accuracy: 32.300000000000004%, Validation Accuracy: 36.038%\n",
      "save best weights\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 3 Time: 74.0s Train Loss: 0.05045, Validation Loss: 0.04865, Train Accuracy: 34.86%, Validation Accuracy: 37.875%\n",
      "save best weights\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 4 Time: 75.0s Train Loss: 0.04835, Validation Loss: 0.06084, Train Accuracy: 38.3%, Validation Accuracy: 35.562%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 5 Time: 76.0s Train Loss: 0.0463, Validation Loss: 0.05016, Train Accuracy: 41.64%, Validation Accuracy: 40.175%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 6 Time: 76.0s Train Loss: 0.04389, Validation Loss: 0.05567, Train Accuracy: 46.7%, Validation Accuracy: 37.7%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 7 Time: 74.0s Train Loss: 0.04269, Validation Loss: 0.04097, Train Accuracy: 48.42%, Validation Accuracy: 50.449999999999996%\n",
      "save best weights\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 8 Time: 74.0s Train Loss: 0.03939, Validation Loss: 0.0438, Train Accuracy: 52.839999999999996%, Validation Accuracy: 46.800000000000004%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 9 Time: 75.0s Train Loss: 0.03734, Validation Loss: 0.0392, Train Accuracy: 55.559999999999995%, Validation Accuracy: 51.888%\n",
      "save best weights\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 10 Time: 75.0s Train Loss: 0.03558, Validation Loss: 0.03745, Train Accuracy: 57.42%, Validation Accuracy: 56.225%\n",
      "save best weights\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 11 Time: 75.0s Train Loss: 0.03335, Validation Loss: 0.04273, Train Accuracy: 60.940000000000005%, Validation Accuracy: 52.212%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 12 Time: 75.0s Train Loss: 0.03213, Validation Loss: 0.03633, Train Accuracy: 62.739999999999995%, Validation Accuracy: 57.062999999999995%\n",
      "save best weights\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 13 Time: 75.0s Train Loss: 0.02874, Validation Loss: 0.05351, Train Accuracy: 66.24%, Validation Accuracy: 50.83800000000001%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 14 Time: 76.0s Train Loss: 0.02642, Validation Loss: 0.03762, Train Accuracy: 69.1%, Validation Accuracy: 58.138%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 15 Time: 76.0s Train Loss: 0.02501, Validation Loss: 0.03399, Train Accuracy: 71.34%, Validation Accuracy: 61.75000000000001%\n",
      "save best weights\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 16 Time: 76.0s Train Loss: 0.02298, Validation Loss: 0.03656, Train Accuracy: 72.2%, Validation Accuracy: 61.9%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 17 Time: 76.0s Train Loss: 0.02068, Validation Loss: 0.04168, Train Accuracy: 75.62%, Validation Accuracy: 56.537000000000006%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 18 Time: 75.0s Train Loss: 0.0195, Validation Loss: 0.04155, Train Accuracy: 77.82%, Validation Accuracy: 58.575%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 19 Time: 74.0s Train Loss: 0.01737, Validation Loss: 0.04669, Train Accuracy: 80.32000000000001%, Validation Accuracy: 57.663%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 20 Time: 74.0s Train Loss: 0.01644, Validation Loss: 0.04059, Train Accuracy: 81.10000000000001%, Validation Accuracy: 62.724999999999994%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 21 Time: 76.0s Train Loss: 0.0145, Validation Loss: 0.03865, Train Accuracy: 83.44%, Validation Accuracy: 61.787000000000006%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 22 Time: 76.0s Train Loss: 0.01227, Validation Loss: 0.0436, Train Accuracy: 86.38%, Validation Accuracy: 61.625%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 23 Time: 75.0s Train Loss: 0.0114, Validation Loss: 0.04629, Train Accuracy: 86.64%, Validation Accuracy: 62.013%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 24 Time: 75.0s Train Loss: 0.01015, Validation Loss: 0.04694, Train Accuracy: 88.66000000000001%, Validation Accuracy: 62.64999999999999%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 25 Time: 75.0s Train Loss: 0.00789, Validation Loss: 0.04408, Train Accuracy: 91.32000000000001%, Validation Accuracy: 64.0%\n",
      "Current Learning Rate: 0.01\n",
      "Epoch: 26 Time: 75.0s Train Loss: 0.00928, Validation Loss: 0.04822, Train Accuracy: 89.44%, Validation Accuracy: 60.650000000000006%\n",
      "Current Learning Rate: 0.001\n",
      "Epoch: 27 Time: 76.0s Train Loss: 0.00431, Validation Loss: 0.03865, Train Accuracy: 95.56%, Validation Accuracy: 67.225%\n",
      "Current Learning Rate: 0.001\n",
      "Epoch: 28 Time: 74.0s Train Loss: 0.0021, Validation Loss: 0.04018, Train Accuracy: 98.32%, Validation Accuracy: 66.862%\n",
      "Current Learning Rate: 0.001\n",
      "Epoch: 29 Time: 74.0s Train Loss: 0.0013, Validation Loss: 0.04138, Train Accuracy: 99.32%, Validation Accuracy: 67.262%\n"
     ]
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    start_time = time.time()\n",
    "    cur_lr = opt.param_groups[0]['lr']\n",
    "    print(\"Current Learning Rate: {}\".format(cur_lr))\n",
    "    \n",
    "    model.train()\n",
    "    train_loss, train_metric = loss_epoch(model, loss_func, train_dl, opt)\n",
    "    loss_history['train'].append(train_loss)\n",
    "    metric_history['train'].append(train_metric)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_metric = loss_epoch(model, loss_func, val_dl)\n",
    "    loss_history['val'].append(val_loss)\n",
    "    metric_history['val'].append(val_metric)\n",
    "\n",
    "    lr_scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Epoch: {} Time: {}s Train Loss: {}, Validation Loss: {}, Train Accuracy: {}%, Validation Accuracy: {}%\".format(epoch, np.round(time.time() - start_time),\n",
    "                              train_loss, val_loss, train_metric*100, val_metric*100))                              \n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        print(\"save best weights\")\n",
    "        save_dir = os.path.join(save_folder, 'weights_epoch{}.pt'.format(epoch))\n",
    "        torch.save(model.state_dict(), save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구현 & 학습결과\n",
    "- 확실히 이전에 구현했던 모델보다는 모델 사이즈의 경량화가 잘 되어있음.\n",
    "- 과적합이 너무 심함. 아래 항목은 과적합 이유 추측\n",
    "    1. 이미지 전처리 과정의 부재(주요 원인 중 하나)\n",
    "    2. 생각보다 심한 정보의 소실(하지만 이정도로 심하면 타 모델에서 depthwise 기능을 썼을리 없음. 보류)\n",
    "    3. Dropout 등 과적합 방지 기능의 부재(주요 원인 중 하나)\n",
    "    4. 데이터셋 고유 문제 or train / val dataset 간의 불균형\n",
    "        - 추가 실험이 필요하겠지만 원본 or train/val 데이터셋의 문제는 아닐듯함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('torchprac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0ff1e094e6b492951d93cec22f6ab1e25f7ef357c8f5ea922c31c40cbd3bb25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
